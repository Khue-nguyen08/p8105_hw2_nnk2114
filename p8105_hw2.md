p8105_hw2_nnk2114
================

## Question 1

Import the poll data file

``` r
pols_month = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv", na = c ("NA", ".", ""), show_col_types = FALSE ) |>
    janitor:: clean_names() |>
  separate(mon, into = c ("year", "month", "day"), sep = "-") |>
  mutate (month = month.name[as.integer(month)])|> 
  mutate (month = str_to_lower(month)) |>
  mutate (year = as.integer(year)) |>
  mutate (president = case_when (
    prez_dem == 1 ~ "dem",
    prez_dem == 0 ~ "gop"
  )) |>
  select ( !c (prez_dem, prez_gop, day))
```

Import and clean the second data set

``` r
snp = 
  read_csv("./fivethirtyeight_datasets/snp.csv", na = c ("NA", ".", ""), show_col_types = FALSE ) |>
    janitor:: clean_names() |>
   separate(date, into = c ("year", "month", "day"), sep = "/") |>
  mutate (month = month.name[as.integer(month)]) |>
  mutate (year = 2000 + as.integer(year))|>
   mutate (month = str_to_lower(month)) |>
  select (!day) |>
  relocate(year, month)
```

Import and tidy the unemployment data

``` r
unemployment = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv", na = c ("NA", ".", ""), show_col_types = FALSE ) |>
    janitor:: clean_names() |>
  pivot_longer( cols = jan: dec,
                names_to = "month",
                values_to = "unemployed" ) |>
  mutate (
    month = month.name[match(str_to_sentence(month),month.abb)]) |>
mutate (month = str_to_lower(month))
```

Join the data set

``` r
combine_data =
  full_join(pols_month, snp) |>
  full_join(unemployment) |>
  na.omit()
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

*Descriptions of the data*

- The first data set included information of the party affliation
  “gop”\_grand old party_republican and “dem”- democrat from 1947 to
  2015
- The second data set contained the stock market index closing values in
  2001 to 2012
- The third data file showed the unemployment data from January ,1948 to
  June, 2015.

The final data contained 787 rows and 11columns. This data set includes
787 observations and 11 variables.

## Question 2

Importing MrTrashwheel data

``` r
mrtrash_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N653")|>
   janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data 
# round the number of the sports balls 
mutate(
  sports_balls = as.integer(sports_balls, length = 0),
  year = as.integer(year),
  day = day(date),
  wheel = "mr") |>
  select (-date) |>
  relocate (wheel, .after = dumpster) |>
  relocate (year,month, day, .after = wheel) |>
  relocate (sports_balls, .after = last_col())
```

Import and cleaning the Professor Trash Wheel

``` r
prof_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:N653")|>
  # use the reasonable name
  janitor::clean_names() |>
  select (-x14) |>
  drop_na()|>
  mutate (
    day = day(date),
    wheel = "prof"
  )|>
  select (-date) |>
  relocate (wheel, .after = dumpster) |>
  relocate (year, month, day, .after = wheel)
```

    ## New names:
    ## • `` -> `...14`

Cleaning the Gwynda sheet

``` r
gwynnda_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:N653")|>
  # use the reasonable name
  janitor::clean_names() |>
  select (- x13, - x14) |>
  #drop_na()|>
  mutate (
    day = day(date),
    wheel = "gwynnda"
  )|>
  select (-date) |>
  relocate (wheel, .after = dumpster) |>
  relocate (year, month, day, .after = wheel)
```

    ## New names:
    ## • `` -> `...13`
    ## • `` -> `...14`

Joining the data set

``` r
joined_trash = 
  full_join (mrtrash_df, prof_df, by = NULL) |>
  full_join (gwynnda_df, by = NULL)
```

    ## Joining with `by = join_by(dumpster, wheel, year, month, day, weight_tons,
    ## volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    ## glass_bottles, plastic_bags, wrappers, homes_powered)`
    ## Joining with `by = join_by(dumpster, wheel, year, month, day, weight_tons,
    ## volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    ## plastic_bags, wrappers, homes_powered)`

*Descriptions of the data*

- The Mr Trash Wheel, Professor Trash Wheel and Gwynnda trash wheel
  contain the data of the types and quantity of trash collwected by
  different water wheel vessel. The Mr Trash data has 651 rows and 15
  columns. It showed that this vessel collected from 651 dumpsters. The
  total time that the trash was collected for 10 years from 2014, 2024.
  Total trash collected was 2091.18.

- The Professor Trash wheel has 117 rows and 14 columns. The data was
  collected from 2017, 2024. Total weigh of collected trash was 244.69.

- The Gwynnda data has 651 rows and 13 columns. The joined data set has
  1419 rows and 15 columns. Total trash collected was NA. Total number
  of cigarette butts collected by Gwynnda in June 2022 is In June 2022,
  Gwynnda Trash Wheel collected 18120 cigarette butts.

``` r
  gwynnda_df |>
  filter(year == 2022, month == "June") |>
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cigarette_butts)
```

    ## [1] 18120

## Question 3

Importing the zipcode data sets

``` r
zipcode_df = 
  read_csv("./zillow_data/Zip Codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(-file_date, -state_fips, -county_fips) |> 
  relocate(county, zip_code)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Importing and tidy the second data set

``` r
zipzori_df =
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = 10: 125,
    names_to = "date",
    values_to =  "price",
    names_prefix = "x"
  ) |>
    separate(
      date, sep = "_",
      into = c ("year", "month", "day")
   )|>
  mutate (
    year = as.integer(year),
    month = as.integer(month)
    ) |>
  select(-state_name, -region_type) |>
  rename(
    zip_code = region_name,
    county = county_name)|>
  mutate(
    county = str_remove(county, " County$")
  ) |>
  relocate(county, zip_code, year, month, day) |>
  drop_na()
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Joining the two data set

``` r
joined_zillow = 
  left_join(
    zipcode_df,zipzori_df, by = c("county", "zip_code")
    ) |> 
  relocate(price, .after = last_col()) |> 
  arrange(year, month, day)
```

Findinng the zipcode that are in the zipcode data but not in the zori
data.

``` r
missing_zip = anti_join(zipcode_df, zipzori_df)
```

    ## Joining with `by = join_by(county, zip_code)`

*Data description*

- There are total 10623 observations and 13 variables.

- In the joined dataset, there are 320 unique zipcodes and 43 unique
  neighborhoods.

- The zipcode that are in the zipcode data but not in the zori data are
  10464, 10474, 10475, 10499, 10550, 10704, 10705, 10803, 11202, 11224,
  11239, 11241, 11242, 11243, 11245, 11247, 11251, 11252, 11256, 11693,
  10008, 10020, 10041, 10043, 10045, 10047, 10048, 10055, 10072, 10080,
  10081, 10082, 10087, 10101, 10102, 10103, 10104, 10105, 10106, 10107,
  10108, 10109, 10110, 10111, 10112, 10113, 10114, 10115, 10116, 10117,
  10118, 10119, 10120, 10121, 10122, 10123, 10124, 10125, 10126, 10129,
  10130, 10131, 10132, 10133, 10138, 10149, 10150, 10151, 10152, 10153,
  10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10163, 10164,
  10165, 10166, 10167, 10168, 10169, 10170, 10171, 10172, 10173, 10174,
  10175, 10176, 10177, 10178, 10179, 10185, 10197, 10199, 10213, 10242,
  10249, 10256, 10259, 10260, 10261, 10265, 10268, 10269, 10270, 10271,
  10272, 10273, 10274, 10275, 10276, 10277, 10278, 10279, 10281, 10285,
  10286, 10292, 10463, 11201, 11001, 11004, 11005, 11040, 11096, 11351,
  11352, 11359, 11362, 11363, 11371, 11380, 11381, 11386, 11405, 11411,
  11412, 11413, 11414, 11416, 11417, 11419, 11420, 11421, 11422, 11423,
  11424, 11425, 11427, 11428, 11429, 11430, 11431, 11433, 11436, 11439,
  11451, 11499, 11559, 11580, 11690, 11694, 11695, 11697, 10302, 10307,
  10309, 10310, 10311, 10313. This could be because no price listed for
  these areas.

Checking the drop price

``` r
drop_price_df =
  joined_zillow|>
  select( county, neighborhood, zip_code, year, month, price)|>
  filter(year %in% c(2020, 2021), month == 1) |> 
  pivot_wider(
    names_from = year,
    values_from = price, 
    names_prefix = "price_"
    ) |>
  mutate (
    price_drop = price_2020 - price_2021
  )|>
   arrange(desc(price_drop))  |> 
  filter (row_number() <= 10) |> 
  select(-month)
```

10 zip codes that had the significant rental price dropped in Jan 2021
compared to Jan 2020

``` r
  drop_price_df |>
 slice_head(n = 10) |> 
  kable(
    col.names = c("Zip Code", "County", "Neighborhood", "Price 2020", "Price 2021", "Price Drop"),
    digits = 0,
    caption = opts_current$get("tab.cap"))
```

| Zip Code | County | Neighborhood | Price 2020 | Price 2021 | Price Drop |
|:---|:---|---:|---:|---:|---:|
| New York | Lower Manhattan | 10007 | 6334 | 5422 | 913 |
| New York | NA | 10069 | 4623 | 3875 | 748 |
| New York | Lower East Side | 10009 | 3406 | 2692 | 714 |
| New York | Gramercy Park and Murray Hill | 10016 | 3731 | 3019 | 712 |
| New York | Chelsea and Clinton | 10001 | 4108 | 3398 | 710 |
| New York | Lower East Side | 10002 | 3645 | 2935 | 710 |
| New York | Lower Manhattan | 10004 | 3150 | 2444 | 706 |
| New York | Lower Manhattan | 10038 | 3573 | 2876 | 698 |
| New York | Greenwich Village and Soho | 10012 | 3629 | 2942 | 686 |
| New York | Gramercy Park and Murray Hill | 10010 | 3697 | 3012 | 685 |

Calculate the percentage drop compared to the price in Jan 2020

``` r
percent_drop =
  drop_price_df |> 
  drop_na() |>
  mutate(
    percentage = (price_drop/ price_2020)*100
  )
```

*Comment*

The neighborhood that had the most price drop in January 2021 compared
to January 2020 were 10007, 10069, 10009, 10016, 10001, 10002, 10004,
10038, 10012, 10010. Other neighborhood included Lower Manhattan, Lower
East Side, Gramercy Park and Murray Hill, Chelsea and Clinton, Lower
East Side, Lower Manhattan, Lower Manhattan, Greenwich Village and Soho,
Gramercy Park and Murray Hill. These were the most crowded area in NYC
before covid. The cost of the rent were also very high. After covid, the
cost were significantly lowered, The highest drop was 912 dollars with
14 percent compared to Jan 2020 rent price. Overall for the top ten
rental price drop, the cost were lower by a range from 14 percent to 22
percent.
