---
title: "p8105_hw2_nnk2114"
output: github_document
---

```{r setup , include = FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
library(dplyr)
library(stringr)
 library(gtsummary)
library(knitr)
```
## Question 1

Import the poll data file 
```{r}
pols_month = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv", na = c ("NA", ".", ""), show_col_types = FALSE ) |>
    janitor:: clean_names() |>
  separate(mon, into = c ("year", "month", "day"), sep = "-") |>
  mutate (month = month.name[as.integer(month)])|> 
  mutate (month = str_to_lower(month)) |>
  mutate (year = as.integer(year)) |>
  mutate (president = case_when (
    prez_dem == 1 ~ "dem",
    prez_dem == 0 ~ "gop"
  )) |>
  select ( !c (prez_dem, prez_gop, day))
  
```

Import and clean the second data set
```{r}
snp = 
  read_csv("./fivethirtyeight_datasets/snp.csv", na = c ("NA", ".", ""), show_col_types = FALSE ) |>
    janitor:: clean_names() |>
   separate(date, into = c ("year", "month", "day"), sep = "/") |>
  mutate (month = month.name[as.integer(month)]) |>
  mutate (year = 2000 + as.integer(year))|>
   mutate (month = str_to_lower(month)) |>
  select (!day) |>
  relocate(year, month)
```
Import and tidy the unemployment data
```{r}
unemployment = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv", na = c ("NA", ".", ""), show_col_types = FALSE ) |>
    janitor:: clean_names() |>
  pivot_longer( cols = jan: dec,
                names_to = "month",
                values_to = "unemployed" ) |>
  mutate (
    month = month.name[match(str_to_sentence(month),month.abb)]) |>
mutate (month = str_to_lower(month))
```

Join the data set 

```{r}
combine_data =
  full_join(pols_month, snp) |>
  full_join(unemployment) |>
  na.omit()
```

*Descriptions of the data*

* The first data set included information of the party affliation "gop"_grand old party_republican and "dem"- democrat from `r pols_month|> pull(year) |> min()` to `r pols_month |> pull(year) |> max()`
* The second data set contained the stock market index closing values in `r snp|> pull(year) |> min()` to `r snp |> pull(year) |> max()`
* The third data file showed the unemployment data from  January ,`r unemployment|> pull(year) |> min()` to June, `r unemployment|> pull(year) |> max()`.

The final data contained `r combine_data |> nrow()` rows and `r combine_data |> ncol()`columns. This data set includes 787 observations and 11 variables. 

## Question 2

Importing MrTrashwheel data

```{r}
mrtrash_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N653")|>
   janitor::clean_names() |>
  # omit rows that do not include dumpster-specific data 
# round the number of the sports balls 
mutate(
  sports_balls = as.integer(sports_balls, length = 0),
  year = as.integer(year),
  day = day(date),
  wheel = "mr") |>
  select (-date) |>
  relocate (wheel, .after = dumpster) |>
  relocate (year,month, day, .after = wheel) |>
  relocate (sports_balls, .after = last_col())
```

Import and cleaning the Professor Trash Wheel

```{r}
prof_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:N653")|>
  # use the reasonable name
  janitor::clean_names() |>
  select (-x14) |>
  drop_na()|>
  mutate (
    day = day(date),
    wheel = "prof"
  )|>
  select (-date) |>
  relocate (wheel, .after = dumpster) |>
  relocate (year, month, day, .after = wheel)
  
```

Cleaning the Gwynda sheet
```{r}
gwynnda_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:N653")|>
  # use the reasonable name
  janitor::clean_names() |>
  select (- x13, - x14) |>
  #drop_na()|>
  mutate (
    day = day(date),
    wheel = "gwynnda"
  )|>
  select (-date) |>
  relocate (wheel, .after = dumpster) |>
  relocate (year, month, day, .after = wheel)
  
```
Joining the data set

```{r}
joined_trash = 
  full_join (mrtrash_df, prof_df, by = NULL) |>
  full_join (gwynnda_df, by = NULL)
```

*Descriptions of the data*

* The Mr Trash Wheel, Professor Trash Wheel and Gwynnda trash wheel contain the data of the types and quantity of trash collwected by different water wheel vessel. 
The Mr Trash data has `r mrtrash_df |> nrow()` rows and `r mrtrash_df |> ncol()` columns. 
It showed that this vessel collected from `r mrtrash_df |> nrow()` dumpsters. 
The total time that the trash was collected for 10 years from `r range(mrtrash_df$year)`. Total trash collected was `r sum(mrtrash_df$weight_tons)`.

* The Professor Trash wheel has `r prof_df |> nrow()` rows and `r prof_df |> ncol()` columns. The data was collected from `r range(prof_df$year)`. Total weigh of collected trash was `r sum(prof_df $ weight_tons)`.

* The Gwynnda data has `r gwynnda_df|> nrow()` rows and `r gwynnda_df|> ncol()` columns.
The joined data set has `r joined_trash |> nrow()` rows and `r joined_trash |> ncol()` columns. Total trash collected was `r sum(gwynnda_df$weight_tons)`.
Total number of cigarette butts collected by Gwynnda in June 2022 is In June 2022, Gwynnda Trash Wheel collected `r format(gwynnda_df |>filter(year == 2022, month == "June") |>summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE))|>pull(total_cigarette_butts), scientific = FALSE)` cigarette butts.


```{r}
  gwynnda_df |>
  filter(year == 2022, month == "June") |>
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(total_cigarette_butts)
```


## Question 3
Importing the zipcode data sets

```{r}
zipcode_df = 
  read_csv("./zillow_data/Zip Codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  select(-file_date, -state_fips, -county_fips) |> 
  relocate(county, zip_code)
```
Importing and tidy the second data set
```{r}
zipzori_df =
  read_csv("./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = 10: 125,
    names_to = "date",
    values_to =  "price",
    names_prefix = "x"
  ) |>
    separate(
      date, sep = "_",
      into = c ("year", "month", "day")
   )|>
  mutate (
    year = as.integer(year),
    month = as.integer(month)
    ) |>
  select(-state_name, -region_type) |>
  rename(
    zip_code = region_name,
    county = county_name)|>
  mutate(
    county = str_remove(county, " County$")
  ) |>
  relocate(county, zip_code, year, month, day) |>
  drop_na()
  
```
Joining the two data set

```{r}
joined_zillow = 
  left_join(
    zipcode_df,zipzori_df, by = c("county", "zip_code")
    ) |> 
  relocate(price, .after = last_col()) |> 
  arrange(year, month, day)
```

Findinng the zipcode that are in the zipcode data but not in the zori data.
```{r}
missing_zip = anti_join(zipcode_df, zipzori_df)
```

*Data description*

* There are total `r joined_zillow|> nrow()` observations and `r joined_zillow |> ncol()` variables.

* In the joined dataset, there are `r n_distinct(joined_zillow$zip_code)` unique zipcodes and `r n_distinct (joined_zillow$neighborhood)` unique neighborhoods.

* The zipcode that are  in the zipcode data but not in the zori data are `r format(missing_zip|> pull(zip_code), scientific = FALSE)`. 
This could be because no price listed for these areas. 



Checking the drop price
```{r}
drop_price_df =
  joined_zillow|>
  select( county, neighborhood, zip_code, year, month, price)|>
  filter(year %in% c(2020, 2021), month == 1) |> 
  pivot_wider(
    names_from = year,
    values_from = price, 
    names_prefix = "price_"
    ) |>
  mutate (
    price_drop = price_2020 - price_2021
  )|>
   arrange(desc(price_drop))  |> 
  filter (row_number() <= 10) |> 
  select(-month)

```

 10 zip codes that had the significant rental price dropped in Jan 2021 compared to Jan 2020
```{r}
  drop_price_df |>
 slice_head(n = 10) |> 
  kable(
    col.names = c("Zip Code", "County", "Neighborhood", "Price 2020", "Price 2021", "Price Drop"),
    digits = 0,
    caption = opts_current$get("tab.cap"))
```

Calculate the percentage drop compared to the price in Jan 2020

```{r}
percent_drop =
  drop_price_df |> 
  drop_na() |>
  mutate(
    percentage = (price_drop/ price_2020)*100
  )
```

*Comment*

 The neighborhood that had the most price drop in January 2021 compared to January 2020 were `r format( drop_price_df|> pull(zip_code[1]), scientific = FALSE)`. 
 Other neighborhood included `r drop_price_df |> drop_na () |> pull(unique(neighborhood))`. These were the most crowded area in NYC before covid. The cost of the rent were also very high. After covid, the cost were significantly lowered, 
 The highest drop was `r drop_price_df$price_drop[1]|> as.integer()` dollars with `r percent_drop$percentage[1]|> as.integer()` percent compared to Jan 2020 rent price. 
 Overall for the top ten rental price drop, the cost were lower by a range from  `r percent_drop$percentage |> min()|> as.integer()` percent to `r percent_drop$percentage |> max()|> as.integer()` percent.
 

